{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clf_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXZoXY7Vy-t_"
      },
      "source": [
        "import io\n",
        "import os\n",
        "import math\n",
        "import copy\n",
        "import pickle\n",
        "import zipfile\n",
        "from textwrap import wrap\n",
        "from pathlib import Path\n",
        "from itertools import zip_longest\n",
        "from collections import defaultdict\n",
        "from urllib.error import URLError\n",
        "from urllib.request import urlopen\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F \n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhFBMRXrzLM2",
        "outputId": "c2f09a73-7c0a-484a-ff2a-7a34d4656fff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sy8h_XT3lUx"
      },
      "source": [
        "df_mr_o = pd.read_csv('/gdrive/My Drive/hackathon/data/clf/MegaRelation_hackaton.csv', sep=\";\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPUeQB95Lpre"
      },
      "source": [
        "df_pupil_o = pd.read_csv('/gdrive/My Drive/hackathon/data/clf/Pupil_hackaton.csv', sep=\";\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GowFUp6GeBHb",
        "outputId": "53ab069f-4dd7-4117-ff99-277077d8b3f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lllll = df_pupil_o.columns.to_list()\n",
        "print(lllll)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['id_ученика', 'возраст', 'пол']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j0popemL6Uv"
      },
      "source": [
        "df_pupil = df_pupil_o.drop(['возраст','пол'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn4TImRnNODF"
      },
      "source": [
        "df_pupil.columns = ['id_student']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLcCXJ_ybVid"
      },
      "source": [
        "df_mr = df_mr_o.drop(['id_зачисления',\n",
        "                        'Дата_создания_записи', \n",
        "                        'id_организации', \n",
        "                        'id_заявления', \n",
        "                        'дата_зачисления', \n",
        "                        'дата_отчисления', \n",
        "                        'причина_перевода', \n",
        "                        'предыдущая_запись_зачисления', \n",
        "                        'следующая_запись_зачисления', \n",
        "                        'Плановая_дата_начала_занятий', \n",
        "                        'Плановая_дата_окончания_занятий'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhvJ6ykmNm7M"
      },
      "source": [
        "df_mr.columns = ['status','id_student','id_service']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkrvHkpp2BnS",
        "outputId": "19eff194-f709-45cf-bbbe-537ef5034a2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_mr['status'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3., nan,  2.,  1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf2w7GplQ-Lv",
        "outputId": "a9ed1e36-f111-4271-c460-9ff0ef9130e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_mr['status'].value_counts(dropna=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0    288103\n",
              "3.0    198300\n",
              "1.0    161374\n",
              "NaN     77036\n",
              "Name: status, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3SX6_BOOKIk",
        "outputId": "9cc65056-7879-4048-e6fc-e59d5604feb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_pupil.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2742631 entries, 0 to 2742630\n",
            "Data columns (total 1 columns):\n",
            " #   Column      Dtype\n",
            "---  ------      -----\n",
            " 0   id_student  int64\n",
            "dtypes: int64(1)\n",
            "memory usage: 20.9 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWiSEMqOgLhq",
        "outputId": "305581b0-1eff-4936-b799-0ebff402e953",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_mr.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 724813 entries, 0 to 724812\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count   Dtype  \n",
            "---  ------      --------------   -----  \n",
            " 0   status      647777 non-null  float64\n",
            " 1   id_student  647777 non-null  float64\n",
            " 2   id_service  724813 non-null  int64  \n",
            "dtypes: float64(2), int64(1)\n",
            "memory usage: 16.6 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LsNQLPghRkk"
      },
      "source": [
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "torch.manual_seed(RANDOM_STATE)\n",
        "torch.cuda.manual_seed(RANDOM_STATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNcVlAoV3tjl"
      },
      "source": [
        "# Target Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnX99UYU3raJ"
      },
      "source": [
        "usage_df = df_pupil.merge(df_mr, how='inner', on='id_student')\n",
        "usage_df.drop_duplicates(inplace=True)\n",
        "\n",
        "usage_df = usage_df[['status', 'id_student', 'id_service']]\n",
        "usage_df['status'] = usage_df['status'].apply(lambda x: 1 if x in [1] else 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qa1vu715_Sv",
        "outputId": "0b0bb58d-2ae1-49c2-ff9c-a616543237e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "usage_df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>status</th>\n",
              "      <th>id_student</th>\n",
              "      <th>id_service</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>40555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>144929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>144929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>144984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>40555</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   status  id_student  id_service\n",
              "0       0           1       40555\n",
              "1       0           1      144929\n",
              "2       1           1      144929\n",
              "3       0           1      144984\n",
              "5       0           2       40555"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf4jklKIH_yn"
      },
      "source": [
        "def create_dataset(book_usage):\n",
        "    unique_users = book_usage.id_student.unique()\n",
        "    user_to_index = {old: new for new, old in enumerate(unique_users)}\n",
        "    new_users = book_usage.id_student.map(user_to_index)\n",
        "    \n",
        "    unique_books = book_usage.id_service.unique()\n",
        "    book_to_index = {old: new for new, old in enumerate(unique_books)}\n",
        "    new_books = book_usage.id_service.map(book_to_index)\n",
        "    \n",
        "    n_users = unique_users.shape[0]\n",
        "    n_books = unique_books.shape[0]\n",
        "    \n",
        "    X = pd.DataFrame({'user_id': new_users, 'movie_id': new_books})\n",
        "    y = book_usage['status'].astype(np.float32)\n",
        "    return (n_users, n_books), (X, y), (user_to_index, book_to_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eONkJvcze42M",
        "outputId": "f7e38ca4-4e56-4eea-c8e1-24e3f2ebbf92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(n, m), (X, y), _ = create_dataset(usage_df)\n",
        "print(f'Embeddings: {n} users, {m} books')\n",
        "print(f'Dataset shape: {X.shape}')\n",
        "print(f'Target shape: {y.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embeddings: 289169 users, 26678 books\n",
            "Dataset shape: (540736, 2)\n",
            "Target shape: (540736,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_no-UBpFqiCJ"
      },
      "source": [
        "# "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Nw_U69bfOHm"
      },
      "source": [
        "class ConditionIterator:\n",
        "    \n",
        "    def __init__(self, X, y, batch_size=32, shuffle=True):\n",
        "        X, y = np.asarray(X), np.asarray(y)\n",
        "        \n",
        "        if shuffle:\n",
        "            index = np.random.permutation(X.shape[0])\n",
        "            X, y = X[index], y[index]\n",
        "            \n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.n_batches = int(math.ceil(X.shape[0] // batch_size))\n",
        "        self._current = 0\n",
        "        \n",
        "    def __iter__(self):\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        return self.next()\n",
        "    \n",
        "    def next(self):\n",
        "        if self._current >= self.n_batches:\n",
        "            raise StopIteration()\n",
        "        k = self._current\n",
        "        self._current += 1\n",
        "        bs = self.batch_size\n",
        "        return self.X[k*bs:(k + 1)*bs], self.y[k*bs:(k + 1)*bs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQdE_X7Vf-C4"
      },
      "source": [
        "def batches(X, y, bs=32, shuffle=True):\n",
        "    for xb, yb in ConditionIterator(X, y, bs, shuffle):\n",
        "        xb = torch.LongTensor(xb)\n",
        "        yb = torch.FloatTensor(yb)\n",
        "        yield xb, yb.view(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVIayOgAf-8S",
        "outputId": "a7565ed9-1fe8-4e7e-ef10-d9ecebdd2c80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for x_batch, y_batch in batches(X, y, bs=4):\n",
        "    print(x_batch)\n",
        "    print(y_batch)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 85868,   3846],\n",
            "        [247721,    493],\n",
            "        [ 67820,  14322],\n",
            "        [178434,  23181]])\n",
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdCr_3bRgByx"
      },
      "source": [
        "class EmbeddingNet(nn.Module):\n",
        "\n",
        "    def __init__(self, n_users, n_books,\n",
        "                 n_factors=20, embedding_dropout=0.02, \n",
        "                 hidden=10, dropouts=0.2):\n",
        "        \n",
        "        super().__init__()\n",
        "        hidden = get_list(hidden)\n",
        "        dropouts = get_list(dropouts)\n",
        "        n_last = hidden[-1]\n",
        "        \n",
        "        def gen_layers(n_in):\n",
        "            nonlocal hidden, dropouts\n",
        "            assert len(dropouts) <= len(hidden)\n",
        "            \n",
        "            for n_out, rate in zip_longest(hidden, dropouts):\n",
        "                yield nn.Linear(n_in, n_out)\n",
        "                yield nn.ReLU()\n",
        "                if rate is not None and rate > 0.:\n",
        "                    yield nn.Dropout(rate)\n",
        "                n_in = n_out\n",
        "            \n",
        "        self.u = nn.Embedding(n_users, n_factors)\n",
        "        self.m = nn.Embedding(n_books, n_factors)\n",
        "        self.dropout = nn.Dropout(embedding_dropout)\n",
        "        self.hidden = nn.Sequential(*list(gen_layers(n_factors * 2)))\n",
        "        self.fc = nn.Linear(n_last, 1)\n",
        "        self._init()\n",
        "        \n",
        "    def forward(self, users, books):\n",
        "        features = torch.cat([self.u(users), self.m(books)], dim=1)\n",
        "        x = self.dropout(features)\n",
        "        x = self.hidden(x)\n",
        "        out = torch.sigmoid(self.fc(x))\n",
        "        return out\n",
        "    \n",
        "    def _init(self):\n",
        "        def init(m):\n",
        "            if type(m) == nn.Linear:\n",
        "                torch.nn.init.xavier_uniform_(m.weight)\n",
        "                m.bias.data.fill_(0.01)\n",
        "                \n",
        "        self.u.weight.data.uniform_(-0.05, 0.05)\n",
        "        self.m.weight.data.uniform_(-0.05, 0.05)\n",
        "        self.hidden.apply(init)\n",
        "        init(self.fc)\n",
        "    \n",
        "    \n",
        "def get_list(n):\n",
        "    if isinstance(n, (int, float)):\n",
        "        return [n]\n",
        "    elif hasattr(n, '__iter__'):\n",
        "        return list(n)\n",
        "    raise TypeError('layers configuraiton should be a single number or a list of numbers')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGz7YtTMhLBL"
      },
      "source": [
        "# Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-rM4tIhgaNj"
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.4, random_state=RANDOM_STATE)\n",
        "datasets = {'train': (X_train, y_train), 'val': (X_valid, y_valid)}\n",
        "dataset_sizes = {'train': len(X_train), 'val': len(X_valid)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxsMdbIShjXE"
      },
      "source": [
        "net = EmbeddingNet(\n",
        "    n_users=n, n_books=m, \n",
        "    n_factors=50, hidden=[200, 200, 200], \n",
        "    embedding_dropout=0.05, dropouts=[0.5, 0.5, 0.25])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuNhZtKBlimh",
        "outputId": "4683344b-e951-4958-905c-cb1948c7b14f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "net"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EmbeddingNet(\n",
              "  (u): Embedding(289169, 50)\n",
              "  (m): Embedding(26678, 50)\n",
              "  (dropout): Dropout(p=0.05, inplace=False)\n",
              "  (hidden): Sequential(\n",
              "    (0): Linear(in_features=100, out_features=200, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=200, out_features=200, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=200, out_features=200, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): Dropout(p=0.25, inplace=False)\n",
              "  )\n",
              "  (fc): Linear(in_features=200, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0lmj8SeiP17"
      },
      "source": [
        "lr = 1e-5\n",
        "wd = 1e-5\n",
        "bs = 2000\n",
        "n_epochs = 25\n",
        "patience = 5\n",
        "no_improvements = 0\n",
        "best_loss = np.inf\n",
        "best_weights = None\n",
        "history = []\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "net.to(device)\n",
        "criterion = nn.BCELoss(reduction='sum')\n",
        "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd)\n",
        "iterations_per_epoch = int(math.ceil(dataset_sizes['train'] // bs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCgw5aAwj_cW",
        "outputId": "8474b998-ec0a-4596-9edb-737b0a88ad69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for epoch in range(n_epochs):\n",
        "    stats = {'epoch': epoch + 1, 'total': n_epochs}\n",
        "    \n",
        "    for phase in ('train', 'val'):\n",
        "        training = phase == 'train'\n",
        "        running_loss = 0.0\n",
        "        n_batches = 0\n",
        "        \n",
        "        for batch in batches(*datasets[phase], shuffle=training, bs=bs):\n",
        "            x_batch, y_batch = [b.to(device) for b in batch]\n",
        "            optimizer.zero_grad()\n",
        "        \n",
        "            # compute gradients only during 'train' phase\n",
        "            with torch.set_grad_enabled(training):\n",
        "                outputs = net(x_batch[:, 0], x_batch[:, 1])\n",
        "                loss = criterion(outputs, y_batch)\n",
        "                \n",
        "                # don't update weights and rates when in 'val' phase\n",
        "                if training:\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    \n",
        "            running_loss += loss.item()\n",
        "            \n",
        "        epoch_loss = running_loss / dataset_sizes[phase]\n",
        "        stats[phase] = epoch_loss\n",
        "        \n",
        "        # early stopping: save weights of the best model so far\n",
        "        if phase == 'val':\n",
        "            if epoch_loss < best_loss:\n",
        "                print('loss improvement on epoch: %d' % (epoch + 1))\n",
        "                best_loss = epoch_loss\n",
        "                best_weights = copy.deepcopy(net.state_dict())\n",
        "                no_improvements = 0\n",
        "            else:\n",
        "                no_improvements += 1\n",
        "                \n",
        "    history.append(stats)\n",
        "    print('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
        "    if no_improvements >= patience:\n",
        "        print('early stopping after epoch {epoch:03d}'.format(**stats))\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss improvement on epoch: 1\n",
            "[001/025] train: 0.6928 - val: 0.6773\n",
            "loss improvement on epoch: 2\n",
            "[002/025] train: 0.6628 - val: 0.6487\n",
            "loss improvement on epoch: 3\n",
            "[003/025] train: 0.6349 - val: 0.6226\n",
            "loss improvement on epoch: 4\n",
            "[004/025] train: 0.6109 - val: 0.6024\n",
            "loss improvement on epoch: 5\n",
            "[005/025] train: 0.5956 - val: 0.5917\n",
            "loss improvement on epoch: 6\n",
            "[006/025] train: 0.5880 - val: 0.5872\n",
            "loss improvement on epoch: 7\n",
            "[007/025] train: 0.5845 - val: 0.5844\n",
            "loss improvement on epoch: 8\n",
            "[008/025] train: 0.5812 - val: 0.5808\n",
            "loss improvement on epoch: 9\n",
            "[009/025] train: 0.5769 - val: 0.5764\n",
            "loss improvement on epoch: 10\n",
            "[010/025] train: 0.5713 - val: 0.5704\n",
            "loss improvement on epoch: 11\n",
            "[011/025] train: 0.5639 - val: 0.5623\n",
            "loss improvement on epoch: 12\n",
            "[012/025] train: 0.5538 - val: 0.5518\n",
            "loss improvement on epoch: 13\n",
            "[013/025] train: 0.5403 - val: 0.5369\n",
            "loss improvement on epoch: 14\n",
            "[014/025] train: 0.5221 - val: 0.5177\n",
            "loss improvement on epoch: 15\n",
            "[015/025] train: 0.4983 - val: 0.4936\n",
            "loss improvement on epoch: 16\n",
            "[016/025] train: 0.4703 - val: 0.4680\n",
            "loss improvement on epoch: 17\n",
            "[017/025] train: 0.4400 - val: 0.4436\n",
            "loss improvement on epoch: 18\n",
            "[018/025] train: 0.4113 - val: 0.4225\n",
            "loss improvement on epoch: 19\n",
            "[019/025] train: 0.3868 - val: 0.4072\n",
            "loss improvement on epoch: 20\n",
            "[020/025] train: 0.3668 - val: 0.3956\n",
            "loss improvement on epoch: 21\n",
            "[021/025] train: 0.3506 - val: 0.3884\n",
            "loss improvement on epoch: 22\n",
            "[022/025] train: 0.3375 - val: 0.3839\n",
            "loss improvement on epoch: 23\n",
            "[023/025] train: 0.3261 - val: 0.3805\n",
            "loss improvement on epoch: 24\n",
            "[024/025] train: 0.3176 - val: 0.3774\n",
            "loss improvement on epoch: 25\n",
            "[025/025] train: 0.3081 - val: 0.3760\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDWNUak5tnv0"
      },
      "source": [
        "# Saving model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Cqlg-j_k1Wk"
      },
      "source": [
        "best_model = net.load_state_dict(best_weights)\n",
        "torch.save(best_weights, '/content/best_weights.pt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}