{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "books_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXZoXY7Vy-t_"
      },
      "source": [
        "import io\n",
        "import os\n",
        "import math\n",
        "import copy\n",
        "import pickle\n",
        "import zipfile\n",
        "from textwrap import wrap\n",
        "from pathlib import Path\n",
        "from itertools import zip_longest\n",
        "from collections import defaultdict\n",
        "from urllib.error import URLError\n",
        "from urllib.request import urlopen\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F \n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhFBMRXrzLM2",
        "outputId": "39e80ae3-8b1c-45e0-d33d-c5b82e0001ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sy8h_XT3lUx"
      },
      "source": [
        "examples_df = pd.read_csv('/gdrive/My Drive/hackathon/data/books/examples.csv')\n",
        "issues_df = pd.read_csv('/gdrive/My Drive/hackathon/data/books/issues.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LsNQLPghRkk"
      },
      "source": [
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "torch.manual_seed(RANDOM_STATE)\n",
        "torch.cuda.manual_seed(RANDOM_STATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNcVlAoV3tjl"
      },
      "source": [
        "# Target Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnX99UYU3raJ"
      },
      "source": [
        "usage_df = examples_df.merge(issues_df, how='inner', on='inventory_id')\n",
        "usage_df.drop_duplicates(inplace=True)\n",
        "\n",
        "usage_df = usage_df[['record_id', 'reader_id', 'condition']]\n",
        "usage_df['condition'] = usage_df['condition'].apply(lambda x: 1 if x in [6544, 6545] else 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qa1vu715_Sv",
        "outputId": "6cbfe425-2111-4d6f-abf4-62d7e79eaeb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "usage_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>record_id</th>\n",
              "      <th>reader_id</th>\n",
              "      <th>condition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>375196</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>416672</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>349736</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>379610</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>378839</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   record_id  reader_id  condition\n",
              "0          1     375196          0\n",
              "1          1     416672          0\n",
              "2          1     349736          0\n",
              "3          1     379610          0\n",
              "4          1     378839          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf4jklKIH_yn"
      },
      "source": [
        "def create_dataset(book_usage):\n",
        "    unique_users = book_usage.reader_id.unique()\n",
        "    user_to_index = {old: new for new, old in enumerate(unique_users)}\n",
        "    new_users = book_usage.reader_id.map(user_to_index)\n",
        "    \n",
        "    unique_books = book_usage.record_id.unique()\n",
        "    book_to_index = {old: new for new, old in enumerate(unique_books)}\n",
        "    new_books = book_usage.record_id.map(book_to_index)\n",
        "    \n",
        "    n_users = unique_users.shape[0]\n",
        "    n_books = unique_books.shape[0]\n",
        "    \n",
        "    X = pd.DataFrame({'user_id': new_users, 'movie_id': new_books})\n",
        "    y = book_usage['condition'].astype(np.float32)\n",
        "    return (n_users, n_books), (X, y), (user_to_index, book_to_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eONkJvcze42M",
        "outputId": "9409c1e1-082c-40b8-e6dd-5c99b855a296",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(n, m), (X, y), _ = create_dataset(usage_df)\n",
        "print(f'Embeddings: {n} users, {m} books')\n",
        "print(f'Dataset shape: {X.shape}')\n",
        "print(f'Target shape: {y.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embeddings: 450509 users, 624908 books\n",
            "Dataset shape: (10418067, 2)\n",
            "Target shape: (10418067,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_no-UBpFqiCJ"
      },
      "source": [
        "# "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Nw_U69bfOHm"
      },
      "source": [
        "class ConditionIterator:\n",
        "    \n",
        "    def __init__(self, X, y, batch_size=32, shuffle=True):\n",
        "        X, y = np.asarray(X), np.asarray(y)\n",
        "        \n",
        "        if shuffle:\n",
        "            index = np.random.permutation(X.shape[0])\n",
        "            X, y = X[index], y[index]\n",
        "            \n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.n_batches = int(math.ceil(X.shape[0] // batch_size))\n",
        "        self._current = 0\n",
        "        \n",
        "    def __iter__(self):\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        return self.next()\n",
        "    \n",
        "    def next(self):\n",
        "        if self._current >= self.n_batches:\n",
        "            raise StopIteration()\n",
        "        k = self._current\n",
        "        self._current += 1\n",
        "        bs = self.batch_size\n",
        "        return self.X[k*bs:(k + 1)*bs], self.y[k*bs:(k + 1)*bs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQdE_X7Vf-C4"
      },
      "source": [
        "def batches(X, y, bs=32, shuffle=True):\n",
        "    for xb, yb in ConditionIterator(X, y, bs, shuffle):\n",
        "        xb = torch.LongTensor(xb)\n",
        "        yb = torch.FloatTensor(yb)\n",
        "        yield xb, yb.view(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVIayOgAf-8S",
        "outputId": "559c1068-37ce-4288-cdd7-e47a593d0eb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for x_batch, y_batch in batches(X, y, bs=4):\n",
        "    print(x_batch)\n",
        "    print(y_batch)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 21493,  27482],\n",
            "        [142822,   6351],\n",
            "        [409994, 293722],\n",
            "        [161283, 548785]])\n",
            "tensor([[1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdCr_3bRgByx"
      },
      "source": [
        "class EmbeddingNet(nn.Module):\n",
        "\n",
        "    def __init__(self, n_users, n_books,\n",
        "                 n_factors=50, embedding_dropout=0.02, \n",
        "                 hidden=10, dropouts=0.2):\n",
        "        \n",
        "        super().__init__()\n",
        "        hidden = get_list(hidden)\n",
        "        dropouts = get_list(dropouts)\n",
        "        n_last = hidden[-1]\n",
        "        \n",
        "        def gen_layers(n_in):\n",
        "            nonlocal hidden, dropouts\n",
        "            assert len(dropouts) <= len(hidden)\n",
        "            \n",
        "            for n_out, rate in zip_longest(hidden, dropouts):\n",
        "                yield nn.Linear(n_in, n_out)\n",
        "                yield nn.ReLU()\n",
        "                if rate is not None and rate > 0.:\n",
        "                    yield nn.Dropout(rate)\n",
        "                n_in = n_out\n",
        "            \n",
        "        self.u = nn.Embedding(n_users, n_factors)\n",
        "        self.m = nn.Embedding(n_books, n_factors)\n",
        "        self.dropout = nn.Dropout(embedding_dropout)\n",
        "        self.hidden = nn.Sequential(*list(gen_layers(n_factors * 2)))\n",
        "        self.fc = nn.Linear(n_last, 1)\n",
        "        self._init()\n",
        "        \n",
        "    def forward(self, users, books):\n",
        "        features = torch.cat([self.u(users), self.m(books)], dim=1)\n",
        "        x = self.dropout(features)\n",
        "        x = self.hidden(x)\n",
        "        out = torch.sigmoid(self.fc(x))\n",
        "        return out\n",
        "    \n",
        "    def _init(self):\n",
        "        def init(m):\n",
        "            if type(m) == nn.Linear:\n",
        "                torch.nn.init.xavier_uniform_(m.weight)\n",
        "                m.bias.data.fill_(0.01)\n",
        "                \n",
        "        self.u.weight.data.uniform_(-0.05, 0.05)\n",
        "        self.m.weight.data.uniform_(-0.05, 0.05)\n",
        "        self.hidden.apply(init)\n",
        "        init(self.fc)\n",
        "    \n",
        "    \n",
        "def get_list(n):\n",
        "    if isinstance(n, (int, float)):\n",
        "        return [n]\n",
        "    elif hasattr(n, '__iter__'):\n",
        "        return list(n)\n",
        "    raise TypeError('layers configuraiton should be a single number or a list of numbers')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGz7YtTMhLBL"
      },
      "source": [
        "# Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-rM4tIhgaNj"
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.4, random_state=RANDOM_STATE)\n",
        "datasets = {'train': (X_train, y_train), 'val': (X_valid, y_valid)}\n",
        "dataset_sizes = {'train': len(X_train), 'val': len(X_valid)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxsMdbIShjXE"
      },
      "source": [
        "net = EmbeddingNet(\n",
        "    n_users=n, n_books=m, \n",
        "    n_factors=25, hidden=[50, 50], \n",
        "    embedding_dropout=0.05, dropouts=[0.5, 0.5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuNhZtKBlimh",
        "outputId": "5cc9163f-b57e-4ebf-d5cb-1bbd639ef987",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "net"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EmbeddingNet(\n",
              "  (u): Embedding(450509, 25)\n",
              "  (m): Embedding(624908, 25)\n",
              "  (dropout): Dropout(p=0.05, inplace=False)\n",
              "  (hidden): Sequential(\n",
              "    (0): Linear(in_features=50, out_features=50, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0lmj8SeiP17"
      },
      "source": [
        "lr = 1e-3\n",
        "wd = 1e-5\n",
        "bs = 2000\n",
        "n_epochs = 100\n",
        "patience = 10\n",
        "no_improvements = 0\n",
        "best_loss = np.inf\n",
        "best_weights = None\n",
        "history = []\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "net.to(device)\n",
        "criterion = nn.BCELoss(reduction='sum')\n",
        "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd)\n",
        "iterations_per_epoch = int(math.ceil(dataset_sizes['train'] // bs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCgw5aAwj_cW",
        "outputId": "6d61be0c-c080-4e3f-a8bd-0d8303551c42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for epoch in range(n_epochs):\n",
        "    stats = {'epoch': epoch + 1, 'total': n_epochs}\n",
        "    \n",
        "    for phase in ('train', 'val'):\n",
        "        training = phase == 'train'\n",
        "        running_loss = 0.0\n",
        "        n_batches = 0\n",
        "        \n",
        "        for batch in batches(*datasets[phase], shuffle=training, bs=bs):\n",
        "            x_batch, y_batch = [b.to(device) for b in batch]\n",
        "            optimizer.zero_grad()\n",
        "        \n",
        "            with torch.set_grad_enabled(training):\n",
        "                outputs = net(x_batch[:, 0], x_batch[:, 1])\n",
        "                loss = criterion(outputs, y_batch)\n",
        "                \n",
        "                if training:\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    \n",
        "            running_loss += loss.item()\n",
        "            \n",
        "        epoch_loss = running_loss / dataset_sizes[phase]\n",
        "        stats[phase] = epoch_loss\n",
        "        \n",
        "        if phase == 'val':\n",
        "            if epoch_loss < best_loss:\n",
        "                print('loss improvement on epoch: %d' % (epoch + 1))\n",
        "                best_loss = epoch_loss\n",
        "                best_weights = copy.deepcopy(net.state_dict())\n",
        "                no_improvements = 0\n",
        "            else:\n",
        "                no_improvements += 1\n",
        "                \n",
        "    history.append(stats)\n",
        "    print('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
        "    if no_improvements >= patience:\n",
        "        print('early stopping after epoch {epoch:03d}'.format(**stats))\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss improvement on epoch: 1\n",
            "[001/100] train: 0.3832 - val: 0.3557\n",
            "[002/100] train: 0.3253 - val: 0.3576\n",
            "[003/100] train: 0.3058 - val: 0.3721\n",
            "[004/100] train: 0.2914 - val: 0.3882\n",
            "[005/100] train: 0.2803 - val: 0.4079\n",
            "[006/100] train: 0.2718 - val: 0.4355\n",
            "[007/100] train: 0.2652 - val: 0.4585\n",
            "[008/100] train: 0.2599 - val: 0.4764\n",
            "[009/100] train: 0.2554 - val: 0.4887\n",
            "[010/100] train: 0.2516 - val: 0.5155\n",
            "[011/100] train: 0.2480 - val: 0.5244\n",
            "early stopping after epoch 011\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Cqlg-j_k1Wk"
      },
      "source": [
        "best_model = net.load_state_dict(best_weights)\n",
        "torch.save(net, '/content/book_model.model')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}